// ***DO NOT EDIT THIS FILE - IT IS AUTOMATICALLY GENERATED BY CMAKE***

#include <osgEarth/Shaders>

namespace osgEarth
{
    Shaders::Shaders()
    {
        // AlphaEffect
        AlphaEffectFragment = "AlphaEffect.frag.glsl";
        _sources[AlphaEffectFragment] = OE_MULTILINE($__HASHTAG__version 110\n
\n
$__HASHTAG__pragma vp_entryPoint "oe_alphaEffect_frag"\n
$__HASHTAG__pragma vp_location   "fragment_coloring"\n
$__HASHTAG__pragma vp_order      "0.5"\n
\n
uniform float oe_alphaEffect_alpha;\n
\n
void oe_alphaEffect_frag(inout vec4 color)\n
{\n
    color = color * oe_alphaEffect_alpha;\n
}\n
\n
);


        // Depth Offset
        DepthOffsetVertex = "DepthOffset.vert.glsl";
       _sources[DepthOffsetVertex] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$GLSL_DEFAULT_PRECISION_FLOAT\n
\n
$__HASHTAG__pragma vp_entryPoint "oe_depthOffset_vertex"\n
$__HASHTAG__pragma vp_location   "vertex_view"\n
$__HASHTAG__pragma vp_order      "0.8"\n
\n
uniform float oe_depthOffset_minBias;\n
uniform float oe_depthOffset_maxBias;\n
uniform float oe_depthOffset_minRange;\n
uniform float oe_depthOffset_maxRange;\n
\n
void oe_depthOffset_vertex(inout vec4 vertexView)\n
{\n
    // calculate range to target:\n
    float range = length(vertexView.xyz);\n
\n
    // calculate the depth offset bias for this range:\n
    float ratio = (clamp(range, oe_depthOffset_minRange, oe_depthOffset_maxRange)-oe_depthOffset_minRange)/(oe_depthOffset_maxRange-oe_depthOffset_minRange);\n
    float bias = oe_depthOffset_minBias + ratio * (oe_depthOffset_maxBias-oe_depthOffset_minBias);\n
\n
	// clamp the bias to 1/2 of the range of the vertex. We don't want to \n
    // pull the vertex TOO close to the camera and certainly not behind it.\n
    bias = min(bias, range*0.5);\n
\n
    //   pull the vertex towards the camera.\n
    vec3 pullVec = normalize(vertexView.xyz);\n
    vec3 simVert3 = vertexView.xyz - pullVec*bias;\n
    vertexView = vec4(simVert3, 1.0);\n
}\n
);


       // Draping
       DrapingVertex = "Draping.vert.glsl";
       _sources[DrapingVertex] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$GLSL_DEFAULT_PRECISION_FLOAT\n
\n
$__HASHTAG__pragma vp_entryPoint "oe_overlay_vertex"\n
$__HASHTAG__pragma vp_location   "vertex_view"\n
\n
uniform mat4 oe_overlay_texmatrix;\n
varying vec4 oe_overlay_texcoord;\n
\n
void oe_overlay_vertex(inout vec4 vertexVIEW)\n
{\n
    oe_overlay_texcoord = oe_overlay_texmatrix * vertexVIEW;\n
}\n
);

       DrapingFragment = "Draping.frag.glsl";
       _sources[DrapingFragment] = OE_MULTILINE($__HASHTAG__version $GLSL_VERSION_STR\n
$GLSL_DEFAULT_PRECISION_FLOAT\n
\n
$__HASHTAG__pragma vp_entryPoint "oe_overlay_fragment"\n
$__HASHTAG__pragma vp_location   "fragment_coloring"\n
$__HASHTAG__pragma vp_order      "0.6"\n
\n
uniform bool      oe_isPickCamera;\n
uniform sampler2D oe_overlay_tex;\n
varying vec4      oe_overlay_texcoord;\n
\n
void oe_overlay_fragment( inout vec4 color )\n
{\n
    vec4 texel = texture2DProj(oe_overlay_tex, oe_overlay_texcoord);\n
    vec4 blendedTexel = vec4( mix( color.rgb, texel.rgb, texel.a ), color.a);\n
\n
    float pick = oe_isPickCamera? 1.0 : 0.0;\n
    color = mix(blendedTexel, texel, pick);\n
}\n
\n
);


        // GPU Clamping
        GPUClampingVertex = "GPUClamping.vert.glsl";
        _sources[GPUClampingVertex] = OE_MULTILINE($__HASHTAG__version 120\n
\n
$__HASHTAG__pragma vp_entryPoint "oe_clamp_vertex"\n
$__HASHTAG__pragma vp_location   "vertex_view"\n
$__HASHTAG__pragma vp_order      "0.5"\n
\n
$__HASHTAG__pragma include "GPUClamping.vert.lib.glsl"\n
\n
attribute vec4 oe_clamp_attrs;\n
attribute float oe_clamp_offset;\n
uniform bool oe_clamp_hasAttrs;\n
\n
uniform bool  oe_isGeocentric;\n
uniform float oe_clamp_altitudeOffset;\n
uniform float oe_clamp_horizonDistance2;\n
varying float oe_clamp_alpha;\n
\n
void oe_clamp_vertex(inout vec4 vertexView)\n
{\n
    const float ClampToAnchor = 1.0;\n
\n
    // check distance; alpha out if its beyone the horizon distance.\n
    oe_clamp_alpha = oe_isGeocentric ? \n
        clamp(oe_clamp_horizonDistance2 - (vertexView.z*vertexView.z), 0.0, 1.0) :\n
        1.0;\n
\n
    // if visible, calculate clamping.\n
    // note: no branch divergence in the vertex shader\n
    if ( oe_clamp_alpha > 0.0 )\n
    {\n
        bool relativeToAnchor = oe_clamp_hasAttrs && (oe_clamp_attrs.a == ClampToAnchor);\n
\n
        float verticalOffset = oe_clamp_hasAttrs ? oe_clamp_attrs.z : 0.0;\n
\n
        // if we are using the anchor point, xform it into view space to prepare\n
        // for clamping. Force Z=0 for anchoring.\n
        vec4 pointToClamp = relativeToAnchor?\n
            gl_ModelViewMatrix * vec4(oe_clamp_attrs.xy, 0.0, 1.0) :\n
            vertexView;\n
\n
        // find the clamped point.\n
        vec4  clampedPoint;\n
        float depth;\n
        oe_getClampedViewVertex(pointToClamp, clampedPoint, depth);\n
\n
        float dh = 0.0;\n
\n
        if ( relativeToAnchor )\n
        {\n
            // if we are clamping relative to the anchor point, adjust the HAT based on the\n
            // distance from the anchor point to the terrain. Since distance() is unsigned,\n
            // we use the vector dot product to calculate whether to adjust up or down.\n
            float dist = distance(pointToClamp, clampedPoint);\n
            float dir = dot(clampedPoint-pointToClamp, vertexView-pointToClamp) < 0.0 ? -1.0 : 1.0;\n
            dh += (dist * dir);\n
        }\n
        else\n
        {\n
            // if we are clamping to the terrain, the vertex becomes the\n
            // clamped point.\n
            vertexView.xyz = clampedPoint.xyz/clampedPoint.w;\n
        }\n
\n
        // apply the z-offset if there is one.\n
        float hOffset = dh + oe_clamp_altitudeOffset + verticalOffset;\n
        if ( hOffset != 0.0 )\n
        {\n
            vec3 up;\n
            oe_getClampingUpVector(up);\n
            vertexView.xyz += up * hOffset;\n
        }\n
\n
        // if the clamped depth value is near the far plane, suppress drawing\n
        // to avoid rendering anomalies.\n
        oe_clamp_alpha = 1.0-step(0.9999, depth);\n
    }\n
}\n
\n
);

        GPUClampingFragment = "GPUClamping.frag.glsl";
        _sources[GPUClampingFragment] = OE_MULTILINE($__HASHTAG__version 110\n
$__HASHTAG__pragma vp_entryPoint "oe_clamp_fragment"\n
$__HASHTAG__pragma vp_location   "fragment_coloring"\n
\n
varying float oe_clamp_alpha;\n
\n
void oe_clamp_fragment(inout vec4 color)\n
{\n
    // adjust the alpha component to "hide" geometry beyond the visible horizon.\n
    color.a *= oe_clamp_alpha;\n
}\n
);

        GPUClampingVertexLib = "GPUClamping.vert.lib.glsl";
        _sources[GPUClampingVertexLib] = OE_MULTILINE(// note: this is an include file\n
\n
// depth texture captures by the clamping technique\n
uniform sampler2D oe_clamp_depthTex;\n
\n
// matrix transforming from view space to depth-texture clip space\n
uniform mat4 oe_clamp_cameraView2depthClip;\n
\n
// matrix transform from depth-tecture clip space to view space\n
uniform mat4 oe_clamp_depthClip2cameraView;\n
\n
// Given a vertex in view space, clamp it to the "ground" as represented\n
// by an orthographic depth texture. Return the clamped vertex in view space,\n
// along with the associated depth value.\n
void oe_getClampedViewVertex(in  vec4  vertView,\n
                             out vec4  out_clampedVertView,\n
                             out float out_depth)\n
{\n
    // transform the vertex into the depth texture's clip coordinates.\n
    vec4 vertDepthClip = oe_clamp_cameraView2depthClip * vertView;\n
\n
    // sample the depth map\n
    out_depth = texture2DProj( oe_clamp_depthTex, vertDepthClip ).r;\n
\n
    // now transform into depth-view space so we can apply the height-above-ground:\n
    vec4 clampedVertDepthClip = vec4(vertDepthClip.x, vertDepthClip.y, out_depth, 1.0);\n
\n
    // convert back into view space.\n
    out_clampedVertView = oe_clamp_depthClip2cameraView * clampedVertDepthClip;\n
}\n
\n
// Returns a vector indiciating the "down" direction.\n
void oe_getClampingUpVector(out vec3 up)\n
{\n
    up = normalize(mat3(oe_clamp_depthClip2cameraView) * vec3(0,0,-1));\n
}\n
\n
);


        // DrawInstanced
        InstancingVertex = "Instancing.vert.glsl";
        _sources[InstancingVertex] = OE_MULTILINE($__HASHTAG__version 130\n
$__HASHTAG__extension GL_EXT_gpu_shader4 : enable\n
$__HASHTAG__extension GL_ARB_draw_instanced: enable\n
\n
$__HASHTAG__pragma vp_entryPoint "oe_di_setInstancePosition"\n
$__HASHTAG__pragma vp_location   "vertex_model"\n
$__HASHTAG__pragma vp_order      "0.0"\n
\n
uniform samplerBuffer oe_di_postex_TBO;\n
uniform int			  oe_di_postex_TBO_size;\n
\n
// Stage-global containing object ID\n
uint oe_index_objectid;\n
\n
void oe_di_setInstancePosition(inout vec4 VertexMODEL)\n
{ \n
    int index = 4 * gl_InstanceID;\n
\n
    vec4 m0 = texelFetch(oe_di_postex_TBO, index);\n
    vec4 m1 = texelFetch(oe_di_postex_TBO, index+1); \n
    vec4 m2 = texelFetch(oe_di_postex_TBO, index+2); \n
    vec4 m3 = texelFetch(oe_di_postex_TBO, index+3);\n
\n
    // decode the ObjectID from the last column:\n
    \n
    oe_index_objectid = uint(m3[0]) + (uint(m3[1]) << 8u) + (uint(m3[2]) << 16u) + (uint(m3[3]) << 24u);\n
    \n
    // rebuild positioning matrix and transform the vert. (Note, the matrix is actually\n
    // transposed so we have to reverse the multiplication order.)\n
    VertexMODEL = VertexMODEL * mat4(m0, m1, m2, vec4(0,0,0,1));\n
}\n
\n
);
    }
};
